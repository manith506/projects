DOCUMENT SUMMARY

Importing Required Modules: The code imports various modules from Python libraries such as numpy, pandas, sklearn, matplotlib, and seaborn for data analysis 
                            and machine learning tasks.
Importing DataSet: The code reads a CSV file containing data on heart attack prediction and displays the first five rows of the data frame. The data has 14 columns 
                            and 294 rows, with some missing values represented by question marks1.
Handling Null Values: The code replaces the question marks with NaN values, and drops the columns with more than 50% of null values (slope, ca, and thal)2. 
                            It also uses a SimpleImputer to fill the null values in the chol column with the mean of that column, and drops the remaining rows 
                            with null values3.
Statistical Analysis: The code shows some basic statistics of the data frame, such as shape, columns, info, and isnull. It also plots a heatmap to visualize 
                            the null values.

Data Preprocessing: The page shows how to use label encoder and one hot encoder to transform categorical features into numeric values, such as sex, chest pain type, 
                            and resting electrocardiographic results.
Data Splitting and Scaling: The page shows how to use train_test_split and StandardScaler to split the data into training and testing sets, and to scale the numerical 
                            features such as age, blood pressure, cholesterol, and heart rate.
Classification Analysis: The page shows how to use LogisticRegression to fit a classification model on the training data, and to evaluate its performance on the 
                            testing data using mean squared error and accuracy score.

Confusion Matrix: The web page shows the confusion matrix for the logistic regression model, which is a 2x2 array that compares the actual and predicted labels for 
                            the test data. The confusion matrix indicates that the model correctly classified 45 cases as negative and 14 cases as positive, 
                            while it misclassified 3 cases as positive and 9 cases as negative.
Classification Using Decision Tree: The web page applies a decision tree classifier to the same data and reports the mean squared error (MSE) and the accuracy score. 
                            The MSE is 0.28169014084507044 and the accuracy is 0.7183098591549296, which are worse than the logistic regression model1.
Classification Using Random Forest: The web page applies a random forest classifier to the same data and reports the MSE and the accuracy score. The MSE is 
                            0.15492957746478872 and the accuracy is 0.8450704225352113, which are better than both the logistic regression and the decision 
                            tree models.
Classification Using Support Vector Machine: The web page applies a support vector machine (SVM) classifier to the same data and reports the MSE and the 
                            accuracy score. The MSE and the accuracy are the same as the random forest model, which are 0.15492957746478872 and 0.8450704225352113 
                            respectively.
Conclusion: The web page concludes that the best machine learning algorithm for the data is the random forest classifier, which has the highest accuracy and 
                            the lowest MSE. The web page also reports the final MSE and accuracy values for the random forest model.
